[{"categories":["kubernetes"],"content":"本文介绍通过 Kubernetes Deployment 对象如何去控制一个应用。 ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:0:0","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"一、前言 学习目标: 创建一个 nginx deployment。 使用 kubectl 对 deployment 进行 CRUD。（结合 dashboard 图示） 使用 go 客户端进行上述操作。 默认已经安装了 kubernetes。如果没安装，请参考搭建 minikube ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:1:0","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"二、实战操作 ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:2:0","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"2.1 准备 yaml 文件 按照任务创建一个运行 nginx:1.14.2 Docker 镜像的 Deployment: apiVersion:apps/v1# for versions before 1.9.0 use apps/v1beta2kind:Deploymentmetadata:name:nginx-deploymentnamespace:testspec:selector:matchLabels:app:nginxreplicas:2# tells deployment to run 2 pods matching the templatetemplate:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.14.2ports:- containerPort:80文件说明： 在命名空间 test（由 .metadata.namespace 字段标明）创建名为 nginx-deployment（由 .metadata.name 字段标明）的 Deployment。 该 Deployment 创建两个（由 .spec.replicas 字段标明）Pod 副本。 selector 字段定义 Deployment 如何查找要管理的 Pods。 在这里，你只需选择在 Pod 模板中定义的标签（app: nginx）。 不过，更复杂的选择规则是也可能的，只要 Pod 模板本身满足所给规则即可。 说明 matchLabels 字段是 {key,value} 偶对的映射。在 matchLabels 映射中的单个 {key,value} 映射等效于 matchExpressions 中的一个元素，即其 key 字段是 “key”，operator 为 “In”，value 数组仅包含 “value”。在 matchLabels 和 matchExpressions 中给出的所有条件都必须满足才能匹配。 template 字段包含以下子字段： Pod 被使用 labels 字段打上 app: nginx 标签。 Pod 模板规约（即 .template.spec 字段）指示 Pods 运行一个 nginx 容器， 该容器运行版本为 1.14.2 的 nginx Docker Hub镜像。 创建一个容器并使用 name 字段将其命名为 nginx。 ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:2:1","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"2.2 创建 Deployment 1. 运行 yaml 文件创建 也可以通过命令直接创建，参考minikube kubectl apply -f /XXX/document/note/Kubernetes/test/nginx/deployment.yaml 小贴士 说明： 你可以设置 –record 标志将所执行的命令写入资源注解 kubernetes.io/change-cause 中。 这对于以后的检查是有用的。例如，要查看针对每个 Deployment 修订版本所执行过的命令。 2. 查看 deployment 创建情况 kubectl get deployments --namespace=test 输出： NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 2/2 2 2 8d 输出字段说明： NAME 列出了集群中 Deployment 的名称。 READY 显示应用程序的可用的 副本 数。显示的模式是“就绪个数/期望个数”。 UP-TO-DATE 显示为了达到期望状态已经更新的副本数。 AVAILABLE 显示应用可供用户使用的副本数。 AGE 显示应用程序运行的时间。 3. 查看 Deployment 上线状态： kubectl rollout status deployment.v1.apps/nginx-deployment --namespace=test 输出： deployment \"nginx-deployment\" successfully rolled out 4. 查看 Deployment 创建的 ReplicaSet（rs）： kubectl get rs --namespace=test 输出： NAME DESIRED CURRENT READY AGE nginx-deployment-6b5df77cd8 2 2 2 17h nginx-deployment-74f5bf7bd9 0 0 0 8d nginx-deployment-7c79566d49 0 0 0 17h nginx-deployment-865d6c94c9 0 0 0 17h nginx-deployment-fbb99c8b8 0 0 0 17h 输出字段说明： NAME 列出名字空间中 ReplicaSet 的名称； DESIRED 显示应用的期望副本个数，即在创建 Deployment 时所定义的值。 此为期望状态； CURRENT 显示当前运行状态中的副本个数； READY 显示应用中有多少副本可以为用户提供服务； AGE 显示应用已经运行的时间长度。 5. 展示 Deployment 的更多信息： kubectl describe deployment nginx-deployment --namespace=test 输出： Name: nginx-deployment Namespace: test CreationTimestamp: Thu, 01 Oct 2020 17:12:59 +0800 Labels: \u003cnone\u003e Annotations: deployment.kubernetes.io/revision: 3 kubectl.kubernetes.io/last-applied-configuration: {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"metadata\":{\"annotations\":{},\"name\":\"nginx-deployment\",\"namespace\":\"test\"},\"spec\":{\"replicas\":... Selector: app=nginx Replicas: 2 desired | 2 updated | 2 total | 2 available | 0 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 25% max unavailable, 25% max surge Pod Template: Labels: app=nginx Containers: nginx: Image: nginx:1.14.2 Port: 80/TCP Host Port: 0/TCP Limits: memory: 200Mi Requests: memory: 100Mi Environment: \u003cnone\u003e Mounts: \u003cnone\u003e Volumes: \u003cnone\u003e Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable OldReplicaSets: \u003cnone\u003e NewReplicaSet: nginx-deployment-fbb99c8b8 (2/2 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 5m6s deployment-controller Scaled up replica set nginx-deployment-865d6c94c9 to 1 Normal ScalingReplicaSet 3m43s deployment-controller Scaled down replica set nginx-deployment-74f5bf7bd9 to 1 Normal ScalingReplicaSet 3m43s deployment-controller Scaled up replica set nginx-deployment-fbb99c8b8 to 1 Normal ScalingReplicaSet 3m41s deployment-controller Scaled down replica set nginx-deployment-865d6c94c9 to 0 Normal ScalingReplicaSet 3m41s deployment-controller Scaled up replica set nginx-deployment-fbb99c8b8 to 2 Normal ScalingReplicaSet 3m38s deployment-controller Scaled down replica set nginx-deployment-74f5bf7bd9 to 0 输出字段说明： Events rs 根据 deployment 的配置控制 pod 的行为，可以看到当副本数变化时，旧的 rs 缩容到 0，新的 rs 扩容到 2（是从上往下的顺序执行，渐进式，结合下一个小贴士便于理解）。 6. 列出创建的 pods： kubectl get pods -l app=nginx --namespace=test 输出： NAME READY STATUS RESTARTS AGE nginx-deployment-fbb99c8b8-4lpwd 1/1 Running 0 5m28s nginx-deployment-fbb99c8b8-tpd4n 1/1 Running 0 5m26s 小贴士 Deployment 可确保在更新时仅关闭一定数量的 Pod。默认情况下，它确保至少所需 Pods 75% 处于运行状态（最大不可用比例为 25%）。 Deployment 还确保仅所创建 Pod 数量只可能比期望 Pods 数高一点点。 默认情况下，它可确保启动的 Pod 个数比期望个数最多多出 25%（最大峰值 25%）。 7. 查看具体某个 pod 的信息： kubectl describe pod nginx-deployment-fbb99c8b8-4lpwd --namespace=test 输出： Name: nginx-deployment-fbb99c8b8-4lpwd Namespace: test Priority: 0 Node: minikube/192.168.64.3 Start Time: Fri, 09 Oct 2020 15:40:15 +0800 Labels: app=nginx pod-template-hash=fbb99c8b8 Annotations: \u003cnone\u003e Status: Running IP: 172.17.0.9 IPs: IP: 172.17.0.9 Controlled By: ReplicaSet/nginx-deployment-fbb99c8b8 Containers: nginx: Container ID: docker://16da80166234e8f7fdbb2e2bb7accbcc1841213cb2888af6463102675414c00d Image: nginx:1.14.2 Image ID: docker-pullable://nginx@sha256:f7988fb6c02e0ce69257d9bd9cf37ae20a60f1df","date":"2020-10-09","objectID":"/2020/10/run-deployment/:2:2","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"2.3 更新 deployment 更新镜像，把 nginx 从 1.14.2 升级到 1.19.3 1. 直接修改配置文件 apiVersion:apps/v1# for versions before 1.9.0 use apps/v1beta2kind:Deploymentmetadata:name:nginx-deploymentnamespace:testspec:selector:matchLabels:app:nginxreplicas:2# tells deployment to run 2 pods matching the templatetemplate:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.19.3ports:- containerPort:80再次执行 kubectl apply -f 指令。 2. 执行 kubectl 编辑命令 kubectl --record deployment.apps/nginx-deployment set image \\ deployment.v1.apps/nginx-deployment nginx=nginx:1.19.3 --namespace=test 或者 kubectl set image deployment/nginx-deployment nginx=nginx:1.19.3 --record --namespace=test 或者 kubectl edit deployment.v1.apps/nginx-deployment --namespace=test # 等价 kubectl edit deployment/nginx-deployment --namespace=test 编辑效果： edit-deploymentedit-deployment \" edit-deployment 查看新的 pods: kubectl get pods -l app=nginx --namespace=test NAME READY STATUS RESTARTS AGE nginx-deployment-6b5df77cd8-lf2cl 1/1 Running 0 69s nginx-deployment-6b5df77cd8-n52z6 1/1 Running 0 71s 可以看到和之前的名称都是不一样的。 dashboard可以直观看到: PodsPods \" Pods ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:2:3","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"2.4 删除 deployment 通过名称删除deployment: kubectl delete deployment nginx-deployment --namespace=test ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:2:4","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"2.5 改变副本数来弹性伸缩应用 关键参数 replicas 可以设置 pod 的数量，下面例子把 nginx 变成 4 个。 1. 直接修改配置文件 apiVersion:apps/v1# for versions before 1.9.0 use apps/v1beta2kind:Deploymentmetadata:name:nginx-deploymentnamespace:testspec:selector:matchLabels:app:nginxreplicas:4# tells deployment to run 2 pods matching the templatetemplate:metadata:labels:app:nginxspec:containers:- name:nginximage:nginx:1.19.3ports:- containerPort:80再次执行 kubectl apply -f 指令。 查看新的 pods: kubectl get pods -l app=nginx --namespace=test NAME READY STATUS RESTARTS AGE nginx-deployment-6b5df77cd8-5b28p 1/1 Running 0 65s nginx-deployment-6b5df77cd8-b24xd 1/1 Running 0 65s nginx-deployment-6b5df77cd8-lf2cl 1/1 Running 0 17m nginx-deployment-6b5df77cd8-n52z6 1/1 Running 0 17m 2. 执行 kubectl 编辑命令 kubectl scale deployment/nginx-deployment --replicas=10 --namespace=test 扩展点（另起文章学习）： 假设集群启用了Pod 的水平自动缩放， 你可以为 Deployment 设置自动缩放器，并基于现有 Pods 的 CPU 利用率选择 要运行的 Pods 个数下限和上限。 kubectl autoscale deployment/nginx-deployment --min=10 --max=15 --cpu-percent=80 --namespace=test 3. 比例缩放实战 默认的配置 spec:strategy:type:RollingUpdaterollingUpdate:maxUnavailable:25%maxSurge:25%说明 Deployment 会在 .spec.strategy.type==RollingUpdate时，采取 滚动更新的方式更新 Pods。你可以指定 maxUnavailable 和 maxSurge 来控制滚动更新 过程。 最大不可用 .spec.strategy.rollingUpdate.maxUnavailable 是一个可选字段，用来指定 更新过程中不可用的 Pod 的个数上限。该值可以是绝对数字（例如，5），也可以是 所需 Pods 的百分比（例如，10%）。百分比值会转换成绝对数并去除小数部分。 如果 .spec.strategy.rollingUpdate.maxSurge 为 0，则此值不能为 0。 默认值为 25%。 最大峰值 .spec.strategy.rollingUpdate.maxSurge 是一个可选字段，用来指定可以创建的超出 期望 Pod 个数的 Pod 数量。此值可以是绝对数（例如，5）或所需 Pods 的百分比（例如，10%）。 如果 MaxUnavailable 为 0，则此值不能为 0。百分比值会通过向上取整转换为绝对数。 此字段的默认值为 25%。 更新 Deployment 使用新镜像，碰巧该镜像无法从集群内部解析。 kubectl set image deployment/nginx-deployment nginx=nginx:sometag --namespace=test 输出： deployment.apps/nginx-deployment image updated 镜像更新使用新的 ReplicaSet nginx-deployment-86dc975d96 启动上线过程，但由于默认 maxUnavailable 的要求会被阻塞。检查上线状态： kubectl get rs --namespace=test 输出： NAME DESIRED CURRENT READY AGE nginx-deployment-6b5df77cd8 2 2 2 18h nginx-deployment-86dc975d96 1 1 0 112s dashboard: PodsPods \" Pods 查看 deployment 创建情况 kubectl get deploy --namespace=test 输出： NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 2/2 1 2 8d 变更 Deployment 副本数到 10 kubectl scale deployment/nginx-deployment --replicas=10 --namespace=test 输出： deployment.apps/nginx-deployment scaled 再次查看 deployment 创建情况 kubectl get deploy --namespace=test 输出： NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 8/10 5 8 8d 确认上线状态 kubectl get rs --namespace=test 输出： NAME DESIRED CURRENT READY AGE nginx-deployment-6b5df77cd8 8 8 8 18h nginx-deployment-86dc975d96 5 5 0 6m56s 说明： 10 个 pod，25% 不可用，所以不能超过 3 个，10 - 2 = 8 个可用，25% 的最大值，就是 12.5，向上取整 13， 8 + 5 = 13。 ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:2:5","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"2.6 回滚 deployment 回滚是 CI/CD 中重要的一个环节，在 kubernetes 面向镜像的无状态服务很好的支持了回滚这个操作。在学习这段内容之前我的做法是直接更新镜像到之前的版本。 默认情况下，Deployment 的所有上线记录都保留在系统中，以便可以随时回滚 （你可以通过修改修订历史记录限制来更改这一约束）。 小贴士 Deployment 被触发上线时，系统就会创建 Deployment 的新的修订版本。 这意味着仅当 Deployment 的 Pod 模板（.spec.template）发生更改时，才会创建新修订版本 – 例如，模板的标签或容器镜像发生变化。 其他更新，如 Deployment 的扩缩容操作不会创建 Deployment 修订版本。 这是为了方便同时执行手动缩放或自动缩放。 换言之，当你回滚到较早的修订版本时，只有 Deployment 的 Pod 模板部分会被回滚。 回滚操作基于比例缩放实战 查看 pod kubectl get pod --selector app=nginx --namespace=test 输出： NAME READY STATUS RESTARTS AGE nginx-deployment-6b5df77cd8-6wx22 1/1 Running 0 24m nginx-deployment-6b5df77cd8-85q77 1/1 Running 0 24m nginx-deployment-6b5df77cd8-8jstb 1/1 Running 0 24m nginx-deployment-6b5df77cd8-lf2cl 1/1 Running 0 19h nginx-deployment-6b5df77cd8-lg2kz 1/1 Running 0 24m nginx-deployment-6b5df77cd8-n52z6 1/1 Running 0 19h nginx-deployment-6b5df77cd8-nxcrf 1/1 Running 0 24m nginx-deployment-6b5df77cd8-tt44h 1/1 Running 0 24m nginx-deployment-86dc975d96-d9pw7 0/1 ImagePullBackOff 0 24m nginx-deployment-86dc975d96-fx9nr 0/1 ImagePullBackOff 0 24m nginx-deployment-86dc975d96-lfhl4 0/1 ImagePullBackOff 0 24m nginx-deployment-86dc975d96-m252z 0/1 ImagePullBackOff 0 24m nginx-deployment-86dc975d96-p7zcg 0/1 ImagePullBackOff 0 31m 小贴士 Deployment 控制器自动停止有问题的上线过程，并停止对新的 ReplicaSet 扩容。 这行为取决于所指定的 rollingUpdate 参数（具体为 maxUnavailable）。 默认情况下，Kubernetes 将此值设置为 25%。 获取 Deployment 描述信息 kubectl describe deployment nginx-deployment --namespace=test 输出： Name: nginx-deployment Namespace: test CreationTimestamp: Thu, 01 Oct 2020 17:12:59 +0800 Labels: \u003cnone\u003e Annotations: deployment.kubernetes.io/revision: 8 kubectl.kubernetes.io/last-applied-configuration: {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"metadata\":{\"annotations\":{},\"name\":\"nginx-deployment\",\"namespace\":\"test\"},\"spec\":{\"replicas\":... Selector: app=nginx Replicas: 10 desired | 5 updated | 13 total | 8 available | 5 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 25% max unavailable, 25% max surge Pod Template: Labels: app=nginx Containers: nginx: Image: nginx:sometag Port: 80/TCP Host Port: 0/TCP Limits: memory: 200Mi Requests: memory: 100Mi Environment: \u003cnone\u003e Mounts: \u003cnone\u003e Volumes: \u003cnone\u003e Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing False ProgressDeadlineExceeded OldReplicaSets: nginx-deployment-6b5df77cd8 (8/8 replicas created) NewReplicaSet: nginx-deployment-86dc975d96 (5/5 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 34m deployment-controller Scaled up replica set nginx-deployment-86dc975d96 to 1 Normal ScalingReplicaSet 27m deployment-controller Scaled up replica set nginx-deployment-6b5df77cd8 to 9 Normal ScalingReplicaSet 27m deployment-controller Scaled up replica set nginx-deployment-86dc975d96 to 4 Normal ScalingReplicaSet 27m deployment-controller Scaled down replica set nginx-deployment-6b5df77cd8 to 8 Normal ScalingReplicaSet 27m deployment-controller Scaled up replica set nginx-deployment-86dc975d96 to 5 2.6.1 检查 deployment 上线历史 检查 Deployment 修订历史 kubectl rollout history deployment/nginx-deployment --namespace=test 输出： deployment.apps/nginx-deployment REVISION CHANGE-CAUSE 1 \u003cnone\u003e 2 \u003cnone\u003e 3 \u003cnone\u003e 6 \u003cnone\u003e 7 \u003cnone\u003e 8 \u003cnone\u003e CHANGE-CAUSE 的内容是从 Deployment 的 kubernetes.io/change-cause 注解复制过来的。 复制动作发生在修订版本创建时。你可以通过以下方式设置 CHANGE-CAUSE 消息： 使用 kubectl annotate deployment.v1.apps/nginx-deployment kubernetes.io/change-cause=“image updated to 1.9.1” 为 Deployment 添加注解。 追加 –record 命令行标志以保存正在更改资源的 kubectl 命令。 手动编辑资源的清单。 查看修订历史的详细信息 kubectl rollout history deployment/nginx-deployment --revision=8 --namespace=test deployment.apps/nginx-deployment with revision #8 Pod Template: Labels: app=nginx pod-template-hash=86dc975d96 Containers: nginx: Image: nginx:sometag Port: 80/TCP Host Port: 0/TCP Limits: memory: 200Mi Requests: memory: 100Mi Environment: \u003cnone\u003e Mounts: \u003cnone\u003e Volumes: \u003cnone\u003e 2.6.2 回滚到之前的修订版本 假定现在你已决定撤消当前上线并回滚到以前的修订版本 kub","date":"2020-10-09","objectID":"/2020/10/run-deployment/:2:6","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"三、API操作 client-go 内容也比较多，这里尽量简单介绍。 ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:3:0","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"3.1 创建 deployment 运行 client-go 示例 func TestCreateDeployment(t *testing.T) { c := getClient() n := \"test\" deployment := \u0026appsv1.Deployment{ ObjectMeta: metav1.ObjectMeta{ Name: \"nginx-deployment\", Namespace: n, }, Spec: appsv1.DeploymentSpec{ Replicas: int32Ptr(4), Selector: \u0026metav1.LabelSelector{ MatchLabels: map[string]string{ \"app\": \"nginx\", }, }, Template: apiv1.PodTemplateSpec{ ObjectMeta: metav1.ObjectMeta{ Labels: map[string]string{ \"app\": \"nginx\", }, }, Spec: apiv1.PodSpec{ Containers: []apiv1.Container{ { Name: \"nginx\", Image: \"nginx:1.19.3\", Ports: []apiv1.ContainerPort{ { ContainerPort: 80, }, }, }, }, }, }, }, } result, err := c.AppsV1().Deployments(n).Create(context.Background(), deployment, metav1.CreateOptions{}) assert.NoError(t, err) t.Logf(\"create deployment result : %v\", result) } 查看部署情况 查看 deployment kubectl get deployments --namespace=test 输出： NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 4/4 4 4 3m4s 查看 pod kubectl get pods -l app=nginx --namespace=test 输出： NAME READY STATUS RESTARTS AGE nginx-deployment-669d59f9b4-7lgz2 1/1 Running 0 5m29s nginx-deployment-669d59f9b4-jmj25 1/1 Running 0 5m29s nginx-deployment-669d59f9b4-kswqx 1/1 Running 0 5m29s nginx-deployment-669d59f9b4-sb5xm 1/1 Running 0 5m29s 查看 rs kubectl get rs --namespace=test 输出： NAME DESIRED CURRENT READY AGE nginx-deployment-669d59f9b4 4 4 4 5m18s ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:3:1","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"3.3 查看 deployment 运行 client-go 示例 func TestGetDeployment(t *testing.T) { c := getClient() n := \"test\" result, err := c.AppsV1().Deployments(n).Get(context.TODO(), \"nginx-deployment\", metav1.GetOptions{}) assert.NoError(t, err) t.Logf(\"get deployment result : %v\", result) } ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:3:2","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"3.2 更新 deployment 运行 client-go 示例 func TestUpdateDeployment(t *testing.T) { c := getClient() n := \"test\" retryErr := retry.RetryOnConflict(retry.DefaultRetry, func() error { // Retrieve the latest version of Deployment before attempting update // RetryOnConflict uses exponential backoff to avoid exhausting the apiserver result, getErr := c.AppsV1().Deployments(n).Get(context.TODO(), \"nginx-deployment\", metav1.GetOptions{}) if getErr != nil { t.Errorf(\"Failed to get latest version of Deployment: %v\", getErr) } result.Spec.Replicas = int32Ptr(2) // reduce replica count result.Spec.Template.Spec.Containers[0].Image = \"nginx:1.14.2\" // change nginx version _, updateErr := c.AppsV1().Deployments(n).Update(context.TODO(), result, metav1.UpdateOptions{}) return updateErr }) if retryErr != nil { t.Errorf(\"Update failed: %v\", retryErr) } } 注意下 RetryOnConflict 说明： // RetryOnConflict is used to make an update to a resource when you have to worry about // conflicts caused by other code making unrelated updates to the resource at the same // time. fn should fetch the resource to be modified, make appropriate changes to it, try // to update it, and return (unmodified) the error from the update function. On a // successful update, RetryOnConflict will return nil. If the update function returns a // \"Conflict\" error, RetryOnConflict will wait some amount of time as described by // backoff, and then try again. On a non-\"Conflict\" error, or if it retries too many times // and gives up, RetryOnConflict will return an error to the caller. 一句话总结就是：当你担心有冲突的时候使用，保障出现冲突错误会自动重试一定的次数直到成功。 查看部署情况 查看 deployment kubectl get deployments --namespace=test 输出： NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 2/2 2 2 25m 查看 pod kubectl get pods -l app=nginx --namespace=test 输出： NAME READY STATUS RESTARTS AGE nginx-deployment-574b87c764-2vlqk 1/1 Running 0 5m4s nginx-deployment-574b87c764-5p9br 1/1 Running 0 5m7s 查看 rs kubectl get rs --namespace=test 输出： NAME DESIRED CURRENT READY AGE nginx-deployment-574b87c764 2 2 2 5m20s nginx-deployment-669d59f9b4 0 0 0 25m ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:3:3","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"3.4 删除 deployment 运行 client-go 示例 func TestDeleteDeployment(t *testing.T) { c := getClient() n := \"test\" deletePolicy := metav1.DeletePropagationForeground if err := c.AppsV1().Deployments(n).Delete(context.TODO(), \"nginx-deployment\", metav1.DeleteOptions{ PropagationPolicy: \u0026deletePolicy, }); err != nil { t.Error(err) } } ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:3:4","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"四、补充信息 ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:4:0","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"4.1 Deployment 动态更新 Deployment 控制器每次注意到新的 Deployment 时，都会创建一个 ReplicaSet 以启动所需的 Pods。 如果更新了 Deployment，则控制标签匹配 .spec.selector 但模板不匹配 .spec.template 的 Pods 的现有 ReplicaSet 被缩容。最终，新的 ReplicaSet 缩放为 .spec.replicas 个副本， 所有旧 ReplicaSets 缩放为 0 个副本。 当 Deployment 正在上线时被更新，Deployment 会针对更新创建一个新的 ReplicaSet 并开始对其扩容，之前正在被扩容的 ReplicaSet 会被翻转，添加到旧 ReplicaSets 列表 并开始缩容。 例如，假定你在创建一个 Deployment 以生成 nginx:1.14.2 的 5 个副本，但接下来 更新 Deployment 以创建 5 个 nginx:1.16.1 的副本，而此时只有 3 个nginx:1.14.2 副本已创建。在这种情况下，Deployment 会立即开始杀死 3 个 nginx:1.14.2 Pods， 并开始创建 nginx:1.16.1 Pods。它不会等待 nginx:1.14.2 的 5 个副本都创建完成 后才开始执行变更动作。 ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:4:1","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"4.2 更改标签选择 通常不鼓励更新标签选择算符。建议你提前规划选择算符。 在任何情况下，如果需要更新标签选择算符，请格外小心，并确保自己了解 这背后可能发生的所有事情。 小贴士 在 API 版本 apps/v1 中，Deployment 标签选择算符在创建后是不可变的。 添加选择算符时要求使用新标签更新 Deployment 规约中的 Pod 模板标签，否则将返回验证错误。 此更改是非重叠的，也就是说新的选择算符不会选择使用旧选择算符所创建的 ReplicaSet 和 Pod， 这会导致创建新的 ReplicaSet 时所有旧 ReplicaSet 都会被孤立。 选择算符的更新如果更改了某个算符的键名，这会导致与添加算符时相同的行为。 删除选择算符的操作会删除从 Deployment 选择算符中删除现有算符。 此操作不需要更改 Pod 模板标签。现有 ReplicaSet 不会被孤立，也不会因此创建新的 ReplicaSet， 但请注意已删除的标签仍然存在于现有的 Pod 和 ReplicaSet 中。 ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:4:2","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"4.3 ReplicaSet 介绍 首先可以看到 nginx 的变化如下图: ReplicaSet 2 扩容到四个节点后: ReplicaSet 4 ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:4:3","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"五、参考 https://kubernetes.io/zh/docs/tasks/run-application/run-stateless-application-deployment/ https://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/ https://kubernetes.io/zh/docs/tasks/administer-cluster/access-cluster-api/ https://github.com/kubernetes/client-go https://kubernetes.io/zh/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/ ","date":"2020-10-09","objectID":"/2020/10/run-deployment/:5:0","tags":["deployment","pod"],"title":"一拳搞定 Kubernetes | 玩转 deployment","uri":"/2020/10/run-deployment/"},{"categories":["kubernetes"],"content":"本文介绍如何在本机mac运行 Minikube 来安装 kubernetes 集群. ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:0:0","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"一、前言 本篇是整个 kubernetes 的开篇，只有安装好了 kubernetes 集群，我们才能愉快的在容器编排的海洋畅游。 为何选择 minikube？因为它只需要按照官方文档执行简单的命令就可以运行，上手简单，推荐使用。 小贴士 自行备好 docker， linux 等常规知识 ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:1:0","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"二、Minikube 操作 安装参考 ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:2:0","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"2-1. 暂停 Minikube minikube stop 输出: * Stopping \"minikube\" in hyperkit ... * \"minikube\" 已停止 ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:2:1","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"2-2. 启动 minikube start 输出: * Darwin 10.15.6 上的 minikube v1.6.2 - KUBECONFIG=/Users/tc/.kube/config.22 * Selecting 'hyperkit' driver from existing profile (alternates: []) * Tip: Use 'minikube start -p \u003cname\u003e' to create a new cluster, or 'minikube delete' to delete this one. * Starting existing hyperkit VM for \"minikube\" ... * Waiting for the host to be provisioned ... ^[* 正在 Docker '19.03.5' 中准备 Kubernetes v1.17.0… * 正在启动 Kubernetes ... * 完成！kubectl 已经配置至 \"minikube\" ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:2:2","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"2-3. 启动 dashboard minikube dashboard 输出: * Verifying dashboard health ... * Launching proxy ... * Verifying proxy health ... * Opening http://127.0.0.1:58368/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ in your default browser... 会自动跳转到浏览器： dashboard ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:2:3","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"2-4. 查看 service 的 URL minikube service hello-minikube --url ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:2:4","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"2-5. 删除 Minikube 集群 minikube delete 输出: * Deleting \"minikube\" ... * The \"minikube\" cluster has been deleted. ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:2:5","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"三、kubernetes 操作 创建 deployment kubectl create deployment hello-minikube --image=k8s.gcr.io/echoserver:1.4 kubectl expose deployment hello-minikube --type=NodePort --port=8080 请注意看这个 --type=NodePort，它表示了服务暴露的模式，也就是你要访问到 k8s 里面一个运行程序的途径。 ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:3:0","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"四、补充说明 ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:4:0","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"3-1. 不能暴露 service 当创建的 service 不加 --type=NodePort，在 minikube 获取不到 service url。 minikube service nginx-deployment --namespace=test --url 输出： |-----------|------------------|-------------|--------------| | NAMESPACE | NAME | TARGET PORT | URL | |-----------|------------------|-------------|--------------| | test | nginx-deployment | | No node port | |-----------|------------------|-------------|--------------| * service test/nginx-deployment has no node port 正常情况输出： http://192.168.64.3:31022 请求这个地址： curl http://192.168.64.3:31022 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eWelcome to nginx!\u003c/title\u003e \u003cstyle\u003e body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eWelcome to nginx!\u003c/h1\u003e \u003cp\u003eIf you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u003c/p\u003e \u003cp\u003eFor online documentation and support please refer to \u003ca href=\"http://nginx.org/\"\u003enginx.org\u003c/a\u003e.\u003cbr/\u003e Commercial support is available at \u003ca href=\"http://nginx.com/\"\u003enginx.com\u003c/a\u003e.\u003c/p\u003e \u003cp\u003e\u003cem\u003eThank you for using nginx.\u003c/em\u003e\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e 有输出，表示请求到了 k8s 集群部署的 nginx。 ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:4:1","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"3-2. dashboard 打不开了 在电脑从公司带回家再次来到公司的时候，出现了一些网络问题，比如 dashboard 无法打开，在浏览器回车 dashboard 地址(http://127.0.0.1:63999/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/#/service?namespace=default)后返回: { \"kind\": \"Status\", \"apiVersion\": \"v1\", \"metadata\": { }, \"status\": \"Failure\", \"message\": \"no endpoints available for service \\\"http:kubernetes-dashboard:\\\"\", \"reason\": \"ServiceUnavailable\", \"code\": 503 } 这时候建议 stop minikube 后再重新启动. ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:4:2","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"3-3. kubeconfig 小贴士 这份配置在后续 client-go 连接集群的时候也会讲到，是访问集群的身份认证信息配置文件。 如上面启动时候的输出一份配置： - KUBECONFIG=/Users/tc/.kube/config.22 这里 KUBECONFIG 是可以通过环境变量指定的，比如我本地： export KUBECONFIG=/Users/tc/.kube/config.22 里面的内容如下： cat /Users/tc/.kube/config.22 apiVersion: v1 clusters: - cluster: certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURBVENDQWVtZ0F3SUJBZ0lKQU91U0IwYkU3VGIrTUEwR0NTcUdTSWIzRFFFQkN3VUFNQmN4RlRBVEJnTlYKQkFNTURERXdMakUxTWk0eE9ETXVNVEFlRncweE9URXlNekF3TmpVek1qTmFGdzAwTnpBMU1UY3dOalV6TWpOYQpNQmN4RlRBVEJnTlZCQU1NRERFd0xqRTFNaTR4T0RNdU1UQ0NBU0l3RFFZSktvWklodmNOQVFFQkJRQURnZ0VQCkFEQ0NBUW9DZ2dFQkFNazV4T2tXb0RXUzdRdFZhOFFCN21DbFFCeC90N2VHdXpEdENYVXYyWU8wcVBJa3RHRVQKaDZkM2dFQ3kzK0ZVVGhDWTF1U2gzYkhDT2wybXJPWnJmN21DelVPdDJZSWQ3QWFVOEVZQzN6dDl6L2d3NTdBWgpWeHE4L3NYZUNQSlBQZXVpOTR0b252cTBSNXNVMm0veTB3UFJMdTFkS052cUV6K05YNFRPUnpCcVpNeVoycXU0CjNMazJCMkNycXJnOXQ1Wks0cU9wQTMwZUxYNHMwVlZUN042RkdFWlRFMTkzdXNLc2dkV2FGb1pJcnh6LzZDbUUKemlDektMcVZiNzAxdWJVZXlCTEU0OER4cVVyZTdtYkoxSWI0VUU5NjE1cDhuSml2UlRJdXZ5aUlxazFieEQ5RwpkaVNEMTdUV1NpTnUwelUyQkJWaEV4OTRYbDcwcENucnhxRUNBd0VBQWFOUU1FNHdIUVlEVlIwT0JCWUVGS29jClFUVE1RYTF1TzZMVk1nVEd0WndsMFNxek1COEdBMVVkSXdRWU1CYUFGS29jUVRUTVFhMXVPNkxWTWdUR3Rad2wKMFNxek1Bd0dBMVVkRXdRRk1BTUJBZjh3RFFZSktvWklodmNOQVFFTEJRQURnZ0VCQUZodlYwVkxGMlRYU0hTLwpGeXBQNG1jMy8vWG9RdWRrUUdNSTJQWDNmNk8xWlBteFVrOGpiMnhiUmJ0aGhTcU5BU0xPSGdSQnRqYjF1UnVaCi96NVliRnhpTEFXdWYyd3FoSzJtRkl4WHg2enF1bExremszRFMxRjZnVWxhYS9hRXoxWW5XdWhUdzArenRtYkkKQkdENnRaTUM3ZDA1YlhseTREQkNtZklPclNNUW14eURvN0IxV1RHWklpd2NwSzN5clJsUEFCc2w5dnJUcit0RQoydUwxaytoYnB3ZjRreVZrNzNRZWdWTGZaK3Q3ZUZRVUpCMDR2V1RSdmtQcVdoTWhqQXRTR1FObG80TVJ3eklWCit2TDUyVGcxZjNXb09LRldyQkQzM1MzOGhLWlpJbzVKUDlPMmxDUU9VRXhRVzZEcmN0UEp0bmhRbHdEUjQ0a04KL1FxNmFNZz0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo= server: https://30.11.44.31:16443 name: microk8s-cluster - cluster: certificate-authority: /Users/tc/.minikube/ca.crt server: https://192.168.64.3:8443 name: minikube contexts: - context: cluster: microk8s-cluster user: admin name: microk8s - context: cluster: minikube user: minikube name: minikube current-context: minikube kind: Config preferences: {} users: - name: admin user: password: d0F2R1hDc2RYUEgxWFA4RGtpWVdFQldHM2xrU0Q2M3czZ3ovK3YzNXJxaz0K username: admin - name: minikube user: client-certificate: /Users/tc/.minikube/client.crt client-key: /Users/tc/.minikube/client.key 也可以执行命令 kubectl config view 是一样的效果。 如果要访问多个 k8s 集群，可以通过在 kubectl 命令加上 --kubeconfig=[位置] 来实现。 ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:4:3","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["kubernetes"],"content":"五、参考 https://kubernetes.io/zh/docs/setup/learning-environment/minikube/ https://minikube.sigs.k8s.io/docs/start/ https://kubernetes.io/zh/docs/concepts/configuration/organize-cluster-access-kubeconfig/ ","date":"2020-10-07","objectID":"/2020/10/minikube-install/:5:0","tags":["minikube"],"title":"一拳搞定 Kubernetes | 安装 Minikube","uri":"/2020/10/minikube-install/"},{"categories":["领域驱动"],"content":"本文介绍一个实际项目中可以使用的概念: Domain Primitive. ","date":"2020-05-28","objectID":"/2020/05/index.zh-cn/:0:0","tags":["DDD","值对象"],"title":"领域驱动实战 | Domain Primitive 的简单使用","uri":"/2020/05/index.zh-cn/"},{"categories":["领域驱动"],"content":"一、前言 领域驱动这个概念也听到很多次了,书上看过的已经忘记,道听途说的不敢苟同（自己也分不清真假,听闻也没一个真正”成功“的案例）,这里我就说一句我的理解:深入挖掘业务内核,找到问题的根本,把复杂问题分为多个领域（领域内聚）去解决业务实际的问题,而不是通过技术角度随着岁月留下一堆跳跃的代码. ","date":"2020-05-28","objectID":"/2020/05/index.zh-cn/:1:0","tags":["DDD","值对象"],"title":"领域驱动实战 | Domain Primitive 的简单使用","uri":"/2020/05/index.zh-cn/"},{"categories":["领域驱动"],"content":"二、本文主角 Domain Primitive ","date":"2020-05-28","objectID":"/2020/05/index.zh-cn/:2:0","tags":["DDD","值对象"],"title":"领域驱动实战 | Domain Primitive 的简单使用","uri":"/2020/05/index.zh-cn/"},{"categories":["领域驱动"],"content":"2.1 Domain Primitive 的定义 概念 不从任何其他事物发展而来 初级的形成或生长的早期阶段 让我们重新来定义一下 Domain Primitive :Domain Primitive 是一个在特定领域里,拥有精准定义的、可自我验证的、拥有行为的 Value Object . • DP是一个传统意义上的Value Object,拥有Immutable的特性 • DP是一个完整的概念整体,拥有精准定义 • DP使用业务域中的原生语言 • DP可以是业务域的最小组成部分、也可以构建复杂组合 注意:Domain Primitive的概念和命名来自于Dan Bergh Johnsson \u0026 Daniel Deogun的书 Secure by Design. ","date":"2020-05-28","objectID":"/2020/05/index.zh-cn/:2:1","tags":["DDD","值对象"],"title":"领域驱动实战 | Domain Primitive 的简单使用","uri":"/2020/05/index.zh-cn/"},{"categories":["领域驱动"],"content":"2.2 使用 Domain Primitive 的三原则 • 让隐性的概念显性化 • 让隐性的上下文显性化 • 封装多对象行为 ","date":"2020-05-28","objectID":"/2020/05/index.zh-cn/:2:2","tags":["DDD","值对象"],"title":"领域驱动实战 | Domain Primitive 的简单使用","uri":"/2020/05/index.zh-cn/"},{"categories":["领域驱动"],"content":"2.3 Domain Primitive 和 DDD 里 Value Object 的区别 在 DDD 中, Value Object 这个概念其实已经存在: • 在 Evans 的 DDD 蓝皮书中,Value Object 更多的是一个非 Entity 的值对象 • 在Vernon的IDDD红皮书中,作者更多的关注了Value Object的Immutability、Equals方法、Factory方法等 Domain Primitive 是 Value Object 的进阶版,在原始 VO 的基础上要求每个 DP 拥有概念的整体,而不仅仅是值对象.在 VO 的 Immutable 基础上增加了 Validity 和行为.当然同样的要求无副作用（side-effect free）. ▍Domain Primitive 和 Data Transfer Object (DTO) 的区别 在日常开发中经常会碰到的另一个数据结构是 DTO ,比如方法的入参和出参.DP 和 DTO 的区别如下: DTO DP 功能 数据传输属于技术细节 业务领域中的概念 数据的关联 只是一堆数据放在一起不一定有关联度 数据之间的高相关新 行为 无行为 丰富的行为和业务逻辑 ","date":"2020-05-28","objectID":"/2020/05/index.zh-cn/:2:3","tags":["DDD","值对象"],"title":"领域驱动实战 | Domain Primitive 的简单使用","uri":"/2020/05/index.zh-cn/"},{"categories":["领域驱动"],"content":"2.4 什么情况下应该用 Domain Primitive 常见的 DP 的使用场景包括: • 有格式限制的 String:比如Name,PhoneNumber,OrderNumber,ZipCode,Address等 • 有限制的Integer:比如OrderId（\u003e0）,Percentage（0-100%）,Quantity（\u003e=0）等 • 可枚举的 int :比如 Status（一般不用Enum因为反序列化问题） • Double 或 BigDecimal:一般用到的 Double 或 BigDecimal 都是有业务含义的,比如 Temperature、Money、Amount、ExchangeRate、Rating 等 • 复杂的数据结构:比如 Map\u003e 等,尽量能把 Map 的所有操作包装掉,仅暴露必要行为 ","date":"2020-05-28","objectID":"/2020/05/index.zh-cn/:2:4","tags":["DDD","值对象"],"title":"领域驱动实战 | Domain Primitive 的简单使用","uri":"/2020/05/index.zh-cn/"},{"categories":["领域驱动"],"content":"三、项目的的尝试 举例子: DP对象 @Getter @JSONType(deserializer = NameDeserializer.class, serializer = NameSerializer.class) public class Name implements Serializable { private static final long serialVersionUID = 7482387369308807214L; private final String name; public Name(final String name) { if (StringUtils.isBlank(name)) { throw new ValidationException(\"名称不能为空!!!\"); } if (!isValid(name)) { throw new ValidationException(\"仅支持1-64位大小写字母,数字,中划线和下划线组成,必须字母开头!!!\"); } this.name = name; } private static boolean isValid(String code) { String pattern = \"^[a-zA-Z][a-zA-Z0-9_-]{1,64}$\"; return code.matches(pattern); } } 领域方法 // 根据应用和Git信息查询流水线发布记录 public PipelineDO queryByAppAndGit(final Name appName, final Git git) { // 进行逻辑处理 } 说明 final 修饰字段,不可变性的特点 构造方法就直接校验合法性,不需要factory和validutil,更内聚自己的功能 因为存在JSON序列化和反序列的情况,这里需要自定义序列化和反序列的方法 效果 前端联调企图传随便的内容进来,直接通不过参数校验,就进不到核心方法了 参数相对更能直观其意,并且进来的参数值取出来肯定是合法的 代码可以写的更少 容易出错的地方 如果用Map做一个缓存,Key放String,而实际对应的是Code对象,那么查询的时候要用code.genCodeString(),一开始容易写code忘记转换,导致查询不到结果 JSON转换在上面已经提到了需要自己定义扩展,会增加一定的重复代码量（我们暂时用的是每个DP类型两个转换类,可以合并到一个方法,根据类型判断,但是语义不够清晰 还没做好的地方 如果通过jar包提供给第三方接口调用也使用这个DP类,那么接口调用方传参不合法的时候就会报错 ","date":"2020-05-28","objectID":"/2020/05/index.zh-cn/:3:0","tags":["DDD","值对象"],"title":"领域驱动实战 | Domain Primitive 的简单使用","uri":"/2020/05/index.zh-cn/"},{"categories":["领域驱动"],"content":"四、参考 阿里云领域驱动DP文章 ","date":"2020-05-28","objectID":"/2020/05/index.zh-cn/:4:0","tags":["DDD","值对象"],"title":"领域驱动实战 | Domain Primitive 的简单使用","uri":"/2020/05/index.zh-cn/"},{"categories":["设计模式"],"content":"本文介绍如何在 go 语言中使用模板模式. ","date":"2019-11-09","objectID":"/2019/11/index.zh-cn/:0:0","tags":["golang","模板模式"],"title":"模板模式","uri":"/2019/11/index.zh-cn/"},{"categories":["设计模式"],"content":"一、前言 Template Pattern（模板模式） 白话文: 定一个“抽象类”,定义一个方法A,定义需要子类实现的方法,所有子类对象在执行A的时候,会调用各自实现的方法. 在golang中,由于不存在抽象类和真正的继承,所以只能通过一个基础类来充当抽象类,子类通过组合基础类来实现通用方法的继承. 故事: 阳光明媚的一天,我家来了位香港的朋友（毕竟那边太乱）,我们决定一起做一桌菜,于是他做香港菜,我做杭州菜,比拼就这么开始了. ","date":"2019-11-09","objectID":"/2019/11/index.zh-cn/:1:0","tags":["golang","模板模式"],"title":"模板模式","uri":"/2019/11/index.zh-cn/"},{"categories":["设计模式"],"content":"二、实例 ","date":"2019-11-09","objectID":"/2019/11/index.zh-cn/:2:0","tags":["golang","模板模式"],"title":"模板模式","uri":"/2019/11/index.zh-cn/"},{"categories":["设计模式"],"content":"2.1 普通例子 代码 package main import ( \"fmt\" \"testing\" ) type Cooking interface { DoOperate() } type AbstractCooking struct { Cooking Prepare func() GetContent func() string } func (d AbstractCooking) DoOperate() { d.Prepare() fmt.Println(\"烹饪内容:\", d.GetContent()) fmt.Println(\"烹饪完成\") } type HZCooking struct { AbstractCooking } func NewHZCooking() *HZCooking { c := new(HZCooking) c.AbstractCooking.GetContent = c.GetContent c.AbstractCooking.Prepare = c.Prepare return c } func (c *HZCooking) GetContent() string { return \"杭州菜.\" } func (c *HZCooking) Prepare() { fmt.Println(\" -- 准备杭州菜 -- \") } type HkCooking struct { HZCooking } func NewHKCooking() *HkCooking { c := new(HkCooking) c.AbstractCooking.GetContent = c.GetContent c.AbstractCooking.Prepare = c.Prepare return c } func (c *HkCooking) GetContent() string { return \"香港菜.\" } func (c *HkCooking) Prepare() { fmt.Println(\" -- 准备香港菜 -- \") } func TestCooking(t *testing.T) { chinaCooking := NewHZCooking() chinaCooking.DoOperate() hkCooking := NewHKCooking() hkCooking.DoOperate() } 输出结果: -- 准备杭州菜 -- 烹饪内容: 杭州菜. 烹饪完成 -- 准备香港菜 -- 烹饪内容: 香港菜. 烹饪完成 ","date":"2019-11-09","objectID":"/2019/11/index.zh-cn/:2:1","tags":["golang","模板模式"],"title":"模板模式","uri":"/2019/11/index.zh-cn/"},{"categories":["设计模式"],"content":"三、参考 https://www.tutorialspoint.com/design_pattern/template_pattern.htm ","date":"2019-11-09","objectID":"/2019/11/index.zh-cn/:3:0","tags":["golang","模板模式"],"title":"模板模式","uri":"/2019/11/index.zh-cn/"},{"categories":["设计模式"],"content":"本文介绍在 go 语言中使用装饰者模式. ","date":"2019-11-04","objectID":"/2019/11/index.zh-cn/:0:0","tags":["golang","装饰者模式"],"title":"装饰者模式","uri":"/2019/11/index.zh-cn/"},{"categories":["设计模式"],"content":"一、前言 Decorator Pattern（装饰模式） 维基百科 This pattern creates a decorator class which wraps the original class and provides additional functionality keeping class methods signature intact. 白话文: 这个模式我们需要创建一个新的装饰类,然后装饰类会拥有一个属性是被装饰类,并且会有“一个”方法和需要使用的被装饰类的方法签名完全一致,调用装饰类的方法会执行装饰类内容并调用被装饰类的被装饰方法. 故事: 我买了一本书《go编程思想》,小明也买了一本书《go编程思想》并给它带上了一个黄金封面,两本书内容一摸一样,只是小明的变成金灿灿的土豪版. ","date":"2019-11-04","objectID":"/2019/11/index.zh-cn/:1:0","tags":["golang","装饰者模式"],"title":"装饰者模式","uri":"/2019/11/index.zh-cn/"},{"categories":["设计模式"],"content":"二、实例 ","date":"2019-11-04","objectID":"/2019/11/index.zh-cn/:2:0","tags":["golang","装饰者模式"],"title":"装饰者模式","uri":"/2019/11/index.zh-cn/"},{"categories":["设计模式"],"content":"2.1 对于某个接口的方法装饰 代码: package decorator import ( \"fmt\" \"testing\" ) type Shape interface { draw() } type Circle struct { } func (shape Circle) draw() { fmt.Println(\"Shape: Circle\") } type Rectangle struct { } func (shape Rectangle) draw() { fmt.Println(\"Shape: Rectangle\") } type ShapeDecorator struct { decoratorShape Shape } func (shape ShapeDecorator) draw() { shape.decoratorShape.draw() } type RedShapeDecorator struct { ShapeDecorator } func NewRedShapeDecorator(s Shape) *RedShapeDecorator { d := new(RedShapeDecorator) d.decoratorShape = s return d } func (shape RedShapeDecorator) draw() { shape.ShapeDecorator.draw() fmt.Println(\"red\") } type BlueShapeDecorator struct { ShapeDecorator } func NewBlueShapeDecorator(s Shape) *BlueShapeDecorator { d := new(BlueShapeDecorator) d.decoratorShape = s return d } func (shape BlueShapeDecorator) draw() { shape.ShapeDecorator.draw() fmt.Println(\"blue\") } func TestName(t *testing.T) { redShapedDecorator := NewRedShapeDecorator(Circle{}) redShapedDecorator.draw() redShapedDecorator = NewRedShapeDecorator(Rectangle{}) redShapedDecorator.draw() blueShapedDecorator := NewBlueShapeDecorator(Circle{}) blueShapedDecorator.draw() blueShapedDecorator = NewBlueShapeDecorator(Rectangle{}) blueShapedDecorator.draw() } 输出结果: Shape: Circle red Shape: Rectangle red Shape: Circle blue Shape: Rectangle blue ","date":"2019-11-04","objectID":"/2019/11/index.zh-cn/:2:1","tags":["golang","装饰者模式"],"title":"装饰者模式","uri":"/2019/11/index.zh-cn/"},{"categories":["设计模式"],"content":"2.2 直接装饰方法 代码: type drawFunc func() func CircleDraw() { fmt.Println(\"Shape: Circle\") } func RedCircleDraw(d drawFunc) drawFunc { return func() { d() fmt.Println(\"red\") } } func TestFunc(t *testing.T) { var drawFunc drawFunc drawFunc = CircleDraw drawFunc() drawFunc = RedCircleDraw(drawFunc) drawFunc() } 输出结果: Shape: Circle Shape: Circle red ","date":"2019-11-04","objectID":"/2019/11/index.zh-cn/:2:2","tags":["golang","装饰者模式"],"title":"装饰者模式","uri":"/2019/11/index.zh-cn/"},{"categories":["设计模式"],"content":"三、参考 https://www.tutorialspoint.com/design_pattern/decorator_pattern.htm ","date":"2019-11-04","objectID":"/2019/11/index.zh-cn/:3:0","tags":["golang","装饰者模式"],"title":"装饰者模式","uri":"/2019/11/index.zh-cn/"},{"categories":["阿里云"],"content":"本文介绍阿里云数据库 binglog 配置注意点. ","date":"2019-09-22","objectID":"/2019/09/aliyun-daily-01/:0:0","tags":["RDS","MySQL","binlog","otter","canal"],"title":"阿里云采坑记录 | RDS 的 binglog 丢失","uri":"/2019/09/aliyun-daily-01/"},{"categories":["阿里云"],"content":"一、前言 上周同事负责的同步服务出现宕机后,由于在忙于另一个重要的项目,线上没有及时处理,后发现同步数据丢失.我趁机了解了下我们的同步逻辑并对这次异常做一个简单的总结. 情况描述: 线上我们基于 otter 的 msyql 数据同步服务出错,出错后会停止数据同步（我们后续的配置没有从中心节点同步到私有云节点）,导致了私有云无法正常启动部分服务. 我们分阿里云（中心节点）,北京私有云节点,广州私有云节点等,数据会从中心节点同步到私有云节点 中心节点使用了阿里云的RDS MySQL数据库,私有云节点采用自己搭建的MySQL 采用基于otter的数据同步服务（otter基于canal） 我们采用了xxl-job来做定时调度,因为之前认为它只有DML操作,我们的同步服务没有对它的DDL操作做处理 xxl-job的机器配置的较低,数据量变大之后XXL_JOB_QRTZ_TRIGGER_LOG的查询语句运行较慢,我们给它增加了个索引 我们的同步服务异常后,会停止数据同步 A服务发布,在中心节点加了配置,私有云节点启动失败 查询发现同步服务异常,无法通过binlog的偏移量找到记录,导致无法把中心节点加了的配置同步到私有云节点 我们是在一天后对这个问题做的处理 ","date":"2019-09-22","objectID":"/2019/09/aliyun-daily-01/:1:0","tags":["RDS","MySQL","binlog","otter","canal"],"title":"阿里云采坑记录 | RDS 的 binglog 丢失","uri":"/2019/09/aliyun-daily-01/"},{"categories":["阿里云"],"content":"二、排查 ","date":"2019-09-22","objectID":"/2019/09/aliyun-daily-01/:2:0","tags":["RDS","MySQL","binlog","otter","canal"],"title":"阿里云采坑记录 | RDS 的 binglog 丢失","uri":"/2019/09/aliyun-daily-01/"},{"categories":["阿里云"],"content":"2.1 xxl job的变化 xxl-job的SQL: SELECT t.id, t.job_group, t.job_id, t.executor_address, t.executor_handler , t.executor_param, t.executor_sharding_param, t.executor_fail_retry_count, t.trigger_time, t.trigger_code , t.trigger_msg, t.handle_time, t.handle_code, t.handle_msg FROM XXL_JOB_QRTZ_TRIGGER_LOG t WHERE t.job_group = ? AND t.job_id = ? AND t.trigger_time \u003e= ? AND t.trigger_time \u003c= ? ORDER BY id DESC LIMIT ?, ? 并没有异常情况. ","date":"2019-09-22","objectID":"/2019/09/aliyun-daily-01/:2:1","tags":["RDS","MySQL","binlog","otter","canal"],"title":"阿里云采坑记录 | RDS 的 binglog 丢失","uri":"/2019/09/aliyun-daily-01/"},{"categories":["阿里云"],"content":"2.2 MySQL 排查 mysql 查看 binlog: // 查看binlog文件列表 mysql\u003e show binary logs; +------------------+-----------+ | Log_name | File_size | +------------------+-----------+ | mysql-bin.000001 | 107853 | +------------------+-----------+ 1 row in set (0.00 sec) // 查看binlog状态 mysql\u003e show master status; +------------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------------+----------+--------------+------------------+-------------------+ | mysql-bin.000001 | 107853 | | | | +------------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 并没有异常情况. ","date":"2019-09-22","objectID":"/2019/09/aliyun-daily-01/:2:2","tags":["RDS","MySQL","binlog","otter","canal"],"title":"阿里云采坑记录 | RDS 的 binglog 丢失","uri":"/2019/09/aliyun-daily-01/"},{"categories":["阿里云"],"content":"三、解决方案 因为同步服务是由于binlog的偏移量问题而失败,偏移量是通过zk节点去获取的,我们去MySQL查询了最新的可用的偏移量,设置到了zk的指定节点,让同步服务正常运行.（我们的配置同步在新偏移量之后,所以启动后能够从中心节点同步到私有云节点） 这个是临时的解决方案,我们没法找到之前的binlog的完整记录 ","date":"2019-09-22","objectID":"/2019/09/aliyun-daily-01/:3:0","tags":["RDS","MySQL","binlog","otter","canal"],"title":"阿里云采坑记录 | RDS 的 binglog 丢失","uri":"/2019/09/aliyun-daily-01/"},{"categories":["阿里云"],"content":"四、思考问题 ","date":"2019-09-22","objectID":"/2019/09/aliyun-daily-01/:4:0","tags":["RDS","MySQL","binlog","otter","canal"],"title":"阿里云采坑记录 | RDS 的 binglog 丢失","uri":"/2019/09/aliyun-daily-01/"},{"categories":["阿里云"],"content":"4.1 为什么过了一天,同步服务会启动失败？ 同步服务失败,因为binlog找不到.MySQL我们自己安装的话binlog配置默认是不清理的,但是RDS上不是这样的. 下面是RDS默认配置: 保留时长:默认值为18,表示实例空间内默认保存最近18个小时内的Binlog文件,18个小时之前的日志将在备份后（需要开启日志备份）清理.保留时长可选范围值为0~7*24小时. 空间使用率不超过:默认值为30%,表示本地Binlog空间使用率大于30%时,系统会从最早的Binlog开始清理,直到空间使用率低于30%.空间使用率不超过可选范围值为0 - 50% . 可用空间保护,默认开启该功能,表示当实例总空间使用率超过80%或实例剩余可用空间不足5GB时,会强制从最早的Binlog开始清理,直到总空间使用率降到80%以下且实例剩余可用空间大于5GB. 我们可以看到RDS默认保留时间小于一天,所以我们停了一天后再度开启,导致binlog位置找不到,只能从最新的偏移量同步.这里首先把保留时长调至3天（我们的同步服务不可能停3天,在某些改造项目,同步服务可能会停1-2天）,这个需要根据实际场景去设置合理的值. ","date":"2019-09-22","objectID":"/2019/09/aliyun-daily-01/:4:1","tags":["RDS","MySQL","binlog","otter","canal"],"title":"阿里云采坑记录 | RDS 的 binglog 丢失","uri":"/2019/09/aliyun-daily-01/"},{"categories":["阿里云"],"content":"4.2 binlog不在了,如何补救？ 阿里云会把binlog保存到OSS,从OSS下载回来binlog,然后把binlog设置到MySQL指定位置（这块可能是我脑补的）.这块有任何问题可以提工单,毕竟顾客是“上帝”. 本地验证的时候,位置是: /usr/local/mysql/data ","date":"2019-09-22","objectID":"/2019/09/aliyun-daily-01/:4:2","tags":["RDS","MySQL","binlog","otter","canal"],"title":"阿里云采坑记录 | RDS 的 binglog 丢失","uri":"/2019/09/aliyun-daily-01/"},{"categories":null,"content":"一个对 Java，Go，云原生和微服务感兴趣的开发人员。 联系我： 邮箱：tczjhz@163.com GitHub：cityiron ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"","uri":"/about/"}]